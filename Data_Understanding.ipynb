{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toRemove</th>\n",
       "      <th>isSarcastic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>@0430yes i hope youre lurking rn. i want to li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>05 really taught me a valuable lesson I'm neve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>@098BERRY Never had a voice to protest, so you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>@0hMySt4rs Rest in peace &amp; love to you and you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TrainSen</td>\n",
       "      <td>0</td>\n",
       "      <td>100 days until Christmas! ðŸŒ² #too soon #not rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toRemove  isSarcastic                                               text\n",
       "0  TrainSen            0  @0430yes i hope youre lurking rn. i want to li...\n",
       "1  TrainSen            0  05 really taught me a valuable lesson I'm neve...\n",
       "2  TrainSen            0  @098BERRY Never had a voice to protest, so you...\n",
       "3  TrainSen            0  @0hMySt4rs Rest in peace & love to you and you...\n",
       "4  TrainSen            0  100 days until Christmas! ðŸŒ² #too soon #not rea..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'Train_v1.txt'\n",
    "column_names = ['toRemove', 'isSarcastic', 'text']\n",
    "\n",
    "# Read the dataset\n",
    "dataset = pd.read_csv(file_path, sep='\\t', header=None, names=column_names)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_mining_utils as tmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isSarcastic    19890\n",
       "text           19890\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19890\n"
     ]
    }
   ],
   "source": [
    "dataset_shuffled = dataset.sample(frac=1, random_state=42)\n",
    "\n",
    "data_sample = len(dataset) // 2\n",
    "dataset = dataset_shuffled.iloc[:data_sample]\n",
    "\n",
    "total_rows = len(dataset)\n",
    "print(total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isSarcastic\n",
      "0    10633\n",
      "1     9257\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = y = dataset['isSarcastic'].value_counts()\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isSarcastic    39780\n",
      "text           39780\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Number of rows for each value in the 'isSarcastic' column:\n",
      "isSarcastic\n",
      "0    21292\n",
      "1    18488\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import My_Preprocessing as prep_funct\n",
    "\n",
    "#prep_funct.remove_Sarcasm_hashtag()\n",
    "\n",
    "dataset = pd.read_json(\"cleaned_#sarcasm.json\")\n",
    "\n",
    "print(dataset.count())\n",
    "sarcastic_counts = dataset['isSarcastic'].value_counts()\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Display the result\n",
    "print(\"Number of rows for each value in the 'isSarcastic' column:\")\n",
    "print(sarcastic_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isSarcastic</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13906</th>\n",
       "      <td>0</td>\n",
       "      <td>Now serving up great coffee from @topecacoffee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27947</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm assuming Greek yogurt is just regular yogu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16807</th>\n",
       "      <td>0</td>\n",
       "      <td>Spread love In this Evening with Manwa Laage.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>1</td>\n",
       "      <td>RT The only benefit of dating a Srilankan girl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22679</th>\n",
       "      <td>1</td>\n",
       "      <td>@BudGirl555 awesome. I cannot wait. Overdue. P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       isSarcastic                                               text\n",
       "13906            0  Now serving up great coffee from @topecacoffee...\n",
       "27947            1  I'm assuming Greek yogurt is just regular yogu...\n",
       "16807            0  Spread love In this Evening with Manwa Laage.....\n",
       "34788            1  RT The only benefit of dating a Srilankan girl...\n",
       "22679            1  @BudGirl555 awesome. I cannot wait. Overdue. P..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "#using functions from text_mining_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   toRemove  isSarcastic                                               text\n",
      "0  TrainSen            0  @0430yes i hope youre lurking rn. i want to li...\n",
      "1  TrainSen            0  05 really taught me a valuable lesson I'm neve...\n",
      "2  TrainSen            0  @098BERRY Never had a voice to protest, so you...\n",
      "3  TrainSen            0  @0hMySt4rs Rest in peace & love to you and you...\n",
      "4  TrainSen            0  100 days until Christmas! ðŸŒ² #too soon #not rea...\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_mining_utils as tmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token '@' appears in the texts with a frequency of 1.46%\n"
     ]
    }
   ],
   "source": [
    "texts = dataset[\"text\"]\n",
    "\n",
    "token = \"@\"\n",
    "\n",
    "#Calculate the percentage of the specified token in the texts\n",
    "percentage = tmu.token_percentage(token, texts)\n",
    "\n",
    "print(f\"The token '{token}' appears in the texts with a frequency of {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#word token stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yogad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcastic_docs = list(dataset.text[dataset.isSarcastic == 1])\n",
    "sarcastic_category = ' '.join(sarcastic_docs)\n",
    "nonsarcastic_docs = list(dataset.text[dataset.isSarcastic == 0])\n",
    "nonsarcastic_category = ' '.join(nonsarcastic_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10 most frequent tokens in isSarcastic ===\n",
      "\tFrequency of \"I\" is: 0.030521333415879197\n",
      "\tFrequency of \".\" is: 0.029395707990252085\n",
      "\tFrequency of \"to\" is: 0.023486174505709737\n",
      "\tFrequency of \"#\" is: 0.020182463881494157\n",
      "\tFrequency of \"the\" is: 0.019861660635190428\n",
      "\tFrequency of \"a\" is: 0.018353322564850096\n",
      "\tFrequency of \"you\" is: 0.016372221815746373\n",
      "\tFrequency of \",\" is: 0.013907102133622994\n",
      "\tFrequency of \"and\" is: 0.013237355005374861\n",
      "\tFrequency of \"my\" is: 0.01100298853550504\n",
      "=== 10 most frequent tokens in notSarcastic ===\n",
      "\tFrequency of \".\" is: 0.027710669227115983\n",
      "\tFrequency of \"I\" is: 0.027674533853682712\n",
      "\tFrequency of \"to\" is: 0.02204773999050156\n",
      "\tFrequency of \"@\" is: 0.021299221540812322\n",
      "\tFrequency of \"the\" is: 0.019177558900658698\n",
      "\tFrequency of \"you\" is: 0.016529352247620227\n",
      "\tFrequency of \"a\" is: 0.015909888703049827\n",
      "\tFrequency of \",\" is: 0.014521257923971175\n",
      "\tFrequency of \"#\" is: 0.013607549195729832\n",
      "\tFrequency of \"and\" is: 0.013241033265192343\n"
     ]
    }
   ],
   "source": [
    "tmu.print_n_mostFrequent('isSarcastic', sarcastic_category, 10)\n",
    "tmu.print_n_mostFrequent('notSarcastic', nonsarcastic_category, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token 'my' appears in the texts with a frequency of 1.04%\n"
     ]
    }
   ],
   "source": [
    "texts = dataset[\"text\"]\n",
    "token = \"my\"\n",
    "\n",
    "# calculate the percentage of the specified token in the texts\n",
    "percentage = tmu.token_percentage(token, texts)\n",
    "\n",
    "print(f\"The token '{token}' appears in the texts with a frequency of {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token 'I' appears in the Sarcastic texts with a frequency of 3.05%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token = \"I\"\n",
    "\n",
    "# calculate the percentage of the specified token in the texts\n",
    "percentage = tmu.token_percentage(token, sarcastic_docs)\n",
    "\n",
    "print(f\"The token '{token}' appears in the Sarcastic texts with a frequency of {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token 'I' appears in the non Sarcastic texts with a frequency of 2.77%\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "\n",
    "token = \"I\"\n",
    "\n",
    "# Calculate the percentage of the specified token in the texts\n",
    "percentage = tmu.token_percentage(token, nonsarcastic_docs)\n",
    "\n",
    "print(f\"The token '{token}' appears in the non Sarcastic texts with a frequency of {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement nltk.corpus (from versions: none)\n",
      "ERROR: No matching distribution found for nltk.corpus\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yogad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yogad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to remove stop words\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply remove_stopwords function to each row in 'text' column\n",
    "stop_words_removed_dataset['text'] = dataset['text'].apply(remove_stopwords)\n",
    "\n",
    "stop_words_removed_dataset['isSarcastic'] = dataset['isSarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcastic_docs_removed = list(stop_words_removed_dataset.text[stop_words_removed_dataset.isSarcastic == 1])\n",
    "sarcastic_category_removed = ' '.join(sarcastic_docs_removed)\n",
    "nonsarcastic_docs_removed = list(stop_words_removed_dataset.text[stop_words_removed_dataset.isSarcastic == 0])\n",
    "nonsarcastic_category_removed = ' '.join(nonsarcastic_docs_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10 most frequent tokens in isSarcastic ===\n",
      "\tFrequency of \".\" is: 0.05064856005619293\n",
      "\tFrequency of \"#\" is: 0.033584640599391244\n",
      "\tFrequency of \",\" is: 0.02314212128307188\n",
      "\tFrequency of \"``\" is: 0.015996253804729573\n",
      "\tFrequency of \"@\" is: 0.014535237649262468\n",
      "\tFrequency of \"n't\" is: 0.014254273003980333\n",
      "\tFrequency of \"'s\" is: 0.011987824865371107\n",
      "\tFrequency of \":\" is: 0.011060641535940061\n",
      "\tFrequency of \"!\" is: 0.011041910559587918\n",
      "\tFrequency of \"love\" is: 0.00954343245141653\n",
      "=== 10 most frequent tokens in notSarcastic ===\n",
      "\tFrequency of \".\" is: 0.044943635856456034\n",
      "\tFrequency of \"@\" is: 0.03385130367720657\n",
      "\tFrequency of \",\" is: 0.023078942618512382\n",
      "\tFrequency of \"#\" is: 0.021626765994453834\n",
      "\tFrequency of \"!\" is: 0.017918382751095287\n",
      "\tFrequency of \"n't\" is: 0.012905501862396009\n",
      "\tFrequency of \"'s\" is: 0.012355807886057463\n",
      "\tFrequency of \"?\" is: 0.008589993928753098\n",
      "\tFrequency of \"``\" is: 0.008524358827100733\n",
      "\tFrequency of \"love\" is: 0.007974664850762187\n"
     ]
    }
   ],
   "source": [
    "tmu.print_n_mostFrequent('isSarcastic', sarcastic_category_removed, 10)\n",
    "tmu.print_n_mostFrequent('notSarcastic', nonsarcastic_category_removed, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#Visualisation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_mining_utils as tmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token ':' appears in the Sarcastic texts with a frequency of 1.11%\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "token = \":\"\n",
    "\n",
    "# Calculate the percentage of the specified token in the texts\n",
    "percentage = tmu.token_percentage(token, sarcastic_docs_removed)\n",
    "\n",
    "print(f\"The token '{token}' appears in the Sarcastic texts with a frequency of {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token ':' appears in the non Sarcastic texts with a frequency of 0.66%\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "\n",
    "token = \":\"\n",
    "\n",
    "# Calculate the percentage of the specified token in the texts\n",
    "percentage = tmu.token_percentage(token, nonsarcastic_docs_removed)\n",
    "\n",
    "print(f\"The token '{token}' appears in the non Sarcastic texts with a frequency of {percentage:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
